{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive DDL and DML â€“ Partitioning and Bucketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hive Partitioning\n",
    "Hive Partitions have a way to organize the tables into partitions by dividing tables into different parts based on partition keys.\n",
    "* list partitioning\n",
    "* hash  partitioning (Clustered By ) \n",
    "* Create a partitioned table as below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "create table `orders_partitioned`(\n",
    "`order_id` int,\n",
    "`order_customer_id` int,\n",
    "`order_status` string)\n",
    "PARTITIONED BY (\n",
    "order_date int\n",
    ") ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Alter Table/Partition/Column***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ALTER TABLE orders_partitioned ADD PARTITION (order_date=20130725);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Data into Partitioned Table\n",
    "Let us see how to insert data into the partitioned table by querying data from the source tables.\n",
    "\n",
    "Here is the command which we can use to insert data into Hive Partitioned table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSERT INTO TABLE orders_partitioned PARTITION (order_date)\n",
    "SELECT order_id, order_customer_id, order_status,\n",
    "cast(date_format(order_date, 'YYYYMMDD') as int) order_date\n",
    "FROM orders_stage WHERE order_date LIKE '2013-07-25';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing using Clustered By\n",
    "Let us see how to create bucketed tables using clustered by.\n",
    "\n",
    "Buckets in the hive are used to partition the data into hash buckets based on the column specified as part of clustered by clause. We need to specify the number of buckets as well.  Bucketing is used for efficient querying.\n",
    "\n",
    "Example for the bucketed table:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "create orders_bucketed (\n",
    " order_id int,\n",
    " order_date string,\n",
    " order_status string,\n",
    " order_customer_id int\n",
    ") clustered by (order_status) into 4 buckets\n",
    " row format delimited fields terminated by  ', ' ;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set hive.enforce.bucketing=true;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert into table orders_bucketed\n",
    "select * from orders01;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hive External Tables\n",
    "Let us see how we can create external tables in Hive.\n",
    "* Syntax for external table is almost same as regular table.\n",
    "* We need to specify EXTERNAL after CREATE for creating external table.\n",
    "* LOCATION is typically specified for EXTERNAL tables.\n",
    "* When we drop external table only structure will be gone, data in HDFS will be intact.\n",
    "\n",
    "### Exercises\n",
    "* create table orders\n",
    "* create table order_items\n",
    "* create table order_items_partitioned\n",
    "    * All fields from order_items\n",
    "    * Partitioned by order_month"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - SQL",
   "language": "sql",
   "name": "apache_toree_sql"
  },
  "language_info": {
   "codemirror_mode": "text/x-sql",
   "file_extension": ".sql",
   "mimetype": "text/x-sql",
   "name": "sql",
   "pygments_lexer": "sql",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
