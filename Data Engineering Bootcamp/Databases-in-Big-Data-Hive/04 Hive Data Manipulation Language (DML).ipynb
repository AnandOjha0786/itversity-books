{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Data Manipulation Language (DML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of this topic, We cover some DDL and DML commands. We will also see about CTAS, the different type of inserting methods into the table and how to create a partitioned table and insert into a partitioned table.\n",
    "\n",
    "### Hive File Formats\n",
    "**DDL** is an abbreviation for Data Definition Language. It is used to create and modify the structure of database objects in the database.\n",
    "\n",
    "**DML** is an abbreviation for Data Manipulation Language. It is used to retrieve, store, modify, delete, insert and update data in the database.\n",
    "* To create CTAS (create table as select) table we can run the command"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "use bootcampdemo_retail_db_txt;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create table orders01 as select * from orders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It will create the new table with the same structure as the original table. But there might be some changes in the metadata of the table.\n",
    "* Like we can see row format changed in the orders01 table.\n",
    "\n",
    "***Creating a table with orc format***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "create table orders_orc\n",
    "stored as orc\n",
    "as \n",
    "select * from orders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By default orc format inherits the row format serde because it has to understand how to read the data and how to write the data.\n",
    "* There are three ways to load the data into hive tables\n",
    "    * Insert Individual records\n",
    "    * Select data from other tables\n",
    "    * Load the data from the files\n",
    "        * Load table in Hive console\n",
    "        * Copy the files directly into HDFS location\n",
    "* The truncate command will delete the data in the table but preserves the structure of the table\n",
    "\n",
    "### Hive Load Command\n",
    "There are two ways to load the data from the local file system, the first one is using put command and the other one is load command.\n",
    "* Create table by using row format delimited by ‘,’\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE `orders`(\n",
    "`order_id` int,\n",
    "`order_date` string,\n",
    "`order_customer_id` int,\n",
    "`order_status` string)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let us copy data directly from HDFS location"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hadoop fs -put /data/retail_db/orders /apps/hive/warehouse/bootcampdemo_retail_db_txt/orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of files is 0 since we copied data from hdfs location directly but it is not updated metadata.\n",
    "* Now let us see loading a local file into the table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load data local inpath /data/retail_db/orders orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To append the same data into the same table we have to specify the file name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hadoop fs -put /data/retail_db/orders /apps/hive/warehouse/bootcampdemo_retail_db_txt/orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we do the same table by loading the data it will update the file name with a new file name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data local inpath /data/retail_db/orders orders"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Original>part-00000_0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "New file>part-0000_copy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To overwrite the data we can use the keyword ‘overwrite’"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load data local inpath /data/retail_db/orders overwrite into table orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hive Insert Command\n",
    "Now let us see the second approach of getting data into a table using insert statement.\n",
    "* We can drop the table using drop command."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "truncate orders;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us truncate table orders_orc so that we can insert into it as we have already inserted data into the table using CTAS."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "truncate orders_orc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inserting data into an existing table by overwriting the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "insert overwrite table orders_orc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "select * from orders_stage;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* creating a table by using partitioned"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE orders_partitioned(\n",
    "order_id INT,\n",
    "order_customer_id INT,\n",
    "order_status STRING\n",
    ")PARTITIONED BY (order_date STRING)\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Insert data into a partitioned table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSERT INTO TABLE orders_partitioned PARTITION (order_date)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT order_id, order_customer_id, order_status, order_date\n",
    "FROM orders_stage;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:It will fail due to dynamic partition mode is not set to nonstrict. We have to set it to nonstrict mode to run and insert data into table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set hive.exec.dynamic.partition.mode=nonstrict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Now run the insert command to insert into a partitioned table\n",
    "* Now we can check the HDFS, it will create partitioned files based on date"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfs -ls /apps/hive/warehouse/bootcampdemo_retail_db_txt.db/orders_partitioned/order_date=2014-05-20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we read the files we can see only three fields since the date become part of the file name."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - SQL",
   "language": "sql",
   "name": "apache_toree_sql"
  },
  "language_info": {
   "codemirror_mode": "text/x-sql",
   "file_extension": ".sql",
   "mimetype": "text/x-sql",
   "name": "sql",
   "pygments_lexer": "sql",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
