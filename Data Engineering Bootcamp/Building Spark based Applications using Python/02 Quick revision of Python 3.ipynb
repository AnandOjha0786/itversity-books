{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick revision of Python 3\n",
    "\n",
    "\n",
    "As part of this topic, let us quickly review the basic concepts of Python before jumping into Spark APIs. Python is a programming language and Spark APIs are compatible with Python (along with Scala, Java etc). It is imperative to master at least one of the programming languages to build applications using Spark.\n",
    "\n",
    "Let us revise below concepts before jumping into pyspark (Spark with Python)\n",
    "\n",
    "Let us revise below concepts before jumping into pyspark (Spark with Python).\n",
    "\n",
    "* Basics of Programming (help, type, indentation etc)\n",
    "* Overview of Functions\n",
    "* Lambda Functions\n",
    "* Basic file I/O\n",
    "* Collections and Map Reduce APIs\n",
    "* Overview of Pandas Data Frames\n",
    "    \n",
    "We can use the jupyter notebook in the lab to revise python concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Programming\n",
    "\n",
    "Let us talk about some of the basics of programming using Python 3.\n",
    "\n",
    "* We can launch python CLI or use Jupyter Notebook to develop Python Code.\n",
    "* <b>type</b> can be used to get the data type of the Python Variable or Object.\n",
    "* <b>help</b> can be used as a CLI or as a function on Class or Object or a Function.\n",
    "* We need to indent properly to define the scope while using Python for Programming.\n",
    "* As Python is dynamically typed programming language we cannot specify data types while creating variable or objects. The type will be inherited based on the value assigned to a variable.\n",
    "* It has all basic constructs such as if, while, for, the ternary operator etc.\n",
    "* <b>Python</b> supports all basic data types as well as collections such as list, set, map etc.\n",
    "* As part of the demo, we will see the usage of a type, help, basic program using the ternary operator as well as looping through a list (get even numbers from a list of elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Functions\n",
    "We need to revise the following related to functions.\n",
    "\n",
    "* Pre-Defined Functions\n",
    " * Performing File I/O\n",
    " * String Manipulation Functions (will see few examples)\n",
    " * Date Manipulation Functions\n",
    " * Manipulating Collections\n",
    " * and more\n",
    "*User Defined Functions\n",
    " * At times we need to develop new functions which are not available as part of Core Python or 3rd party Python modules.\n",
    " * Here are a few things we should recollect with respect to user-defined functions.\n",
    "  * Function Specification (Function Name, Arguments, and Return type)\n",
    "  * We can have a fixed number of arguments, varying number of arguments as well as keyword arguments for Functions in Python.\n",
    "  * Function Definition or Logic\n",
    "  * Return Statement\n",
    "* Functions can be passed as arguments to other functions.\n",
    "* We also will go through lambda functions in a separate topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Functions\n",
    "\n",
    "Let us revise the details related to Lambda Functions\n",
    "\n",
    "* At times we might have to develop simple functions, especially to pass as an argument for higher order functions.\n",
    "* In that case, we can use lambda functions.\n",
    "* Lambda Functions are extensively used as part of modern programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n",
      "sum of integers using conventional approach 12\n",
      "sum of squares using conventional approach 50\n",
      "sum of integers using lambda functions 12\n",
      "sum of squares using lambda functions 50\n",
      "sum of cubes using lambda functions 216\n"
     ]
    }
   ],
   "source": [
    "# Correct way of getting sumOfIntegers\n",
    "def sumOfIntegers(lb, ub):\n",
    "    l = lb - 1\n",
    "    return ((ub * (ub + 1)) / 2) - ((l * (l + 1)) / 2)\n",
    "\n",
    "print(sumOfIntegers(2, 5))\n",
    "\n",
    "# To demonstrate lambda functions we will loop through the range\n",
    "# Conventional approach, we need to write different functions for\n",
    "# sum of range of numbers\n",
    "# sum of squares in range of numbers\n",
    "# and more\n",
    "def sum(lb, ub):\n",
    "    total = 0\n",
    "    for i in range(lb, ub + 1):\n",
    "        total += i\n",
    "    return total\n",
    "print (\"sum of integers using conventional approach \" + str(sum(3, 5)))\n",
    "\n",
    "def sumOfSquares(lb, ub):\n",
    "    total = 0\n",
    "    for i in range(lb, ub + 1):\n",
    "        total += (i * i)\n",
    "    return total\n",
    "print (\"sum of squares using conventional approach \" + str(sumOfSquares(3, 5)))\n",
    "\n",
    "# With lambda functions, we can get more concise and readable code\n",
    "def sum(f, lb, ub):\n",
    "    total = 0\n",
    "    for i in range(lb, ub + 1):\n",
    "        total += f(i)\n",
    "    return total\n",
    "print (\"sum of integers using lambda functions \" + str(sum(lambda i: i, 3, 5)))\n",
    "print (\"sum of squares using lambda functions \" + str(sum(lambda i: i * i, 3, 5)))\n",
    "\n",
    "# We can also pass named function as argument\n",
    "def cube(i): return i * i * i\n",
    "print (\"sum of cubes using lambda functions \" + str(sum(lambda i: cube(i), 3, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic File I/O\n",
    "\n",
    "Let us see how we can read the data using Python File I/O APIs. We will limit the scope to read the data from a file into a collection.\n",
    "\n",
    "* <b>open</b> is the API which facilitates us to create File Object\n",
    "* We can perform <b>read()</b> to read the data from a file into the memory. When we apply read on files of text format, data will be loaded into memory as a string.\n",
    "* We can load data at once or in iterations of multiple batches or buffers.\n",
    "* To convert into the collection we can either use <b>split</b> or <b>splitlines</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections and Map Reduce APIs\n",
    "Now let us recollect details about collections and basic map reduce APIs.\n",
    "\n",
    "* Python support 3 types of Collections\n",
    " * list – **[1, 2, 1, 5, 3]**\n",
    " * set – **{1, 2, 5, 3}**\n",
    " * dict – **{ ‘order_id’: 1, ‘order_date’: ‘2013-07-25 00:00:00.0’, ‘order_customer_id’: 1000, ‘order_status’: ‘COMPLETE’ }**\n",
    " * a list is a heap of items while the set is a group of unique items\n",
    " * dict is similar to a hash map where keys are unique with corresponding value.\n",
    "* We also have another data structure called Tuple. They are unnamed objects where values of attributes can be retrieved using positional notation\n",
    " * tuple – <b>(1, ‘2013-07-25 00:00:00.0’, 1000, ‘COMPLETE’)</b>\n",
    "* Quite often we will create a list or set of tuples\n",
    "* Let us see some simple examples\n",
    " * Creating a list using orders data from a file\n",
    " * Convert one element from the list into a tuple and perform tuple operations.\n",
    " * Extract order_dates from a list and get unique dates using set.\n",
    " * Extract order_id and order_date as dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-07-25 00:00:00.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = open('/data/retail_db/orders/part-00000'). \\\n",
    "read(). \\\n",
    "splitlines()\n",
    "\n",
    "# for order in orders[:10]: print(order)\n",
    "    \n",
    "orderDatesList = []\n",
    "\n",
    "for order in orders:\n",
    "    orderDatesList.append(order.split(',')[1])\n",
    "    \n",
    "orderDates = set(orderDatesList)\n",
    "\n",
    "# for order in list(orderDates)[:10]: print(order)\n",
    "\n",
    "orderRecord = orders[0]\n",
    "orderRecordElements = orders[0].split(',')\n",
    " \n",
    "orderTuple = (int(orderRecordElements[0]), orderRecordElements[1], int(orderRecordElements[2]), orderRecordElements[3])\n",
    "# print(orderTuple[1])\n",
    "\n",
    "orderDict = {}\n",
    "\n",
    "for order in orders:\n",
    "    orderDict[int(order.split(',')[0])] = order.split(',')[1]\n",
    "    \n",
    "print(orderDict[1])\n",
    "len(orderDict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce APIs\n",
    "\n",
    "Let us get into the details related to Map Reduce APIs to manipulate collections.\n",
    "\n",
    "* We can process data in collections using different approaches – conventional loops, map-reduce etc.\n",
    "* Map Reduce APIs such as filter, map etc take care of initializing the aggregator, looping through elements as well as returning the aggregator for us. We just need to focus on business logic.\n",
    "* If we have to sort the collection then we need to convert the collection to list\n",
    "* If we have to eliminate duplicates then we need to convert the collection to set\n",
    "* Let us see how we can create a collection from a file and then apply map reduce APIs to compute revenue for a given order_item_order_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2013-07-25 00:00:00.0,11599,CLOSED\n",
      "2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT\n",
      "3,2013-07-25 00:00:00.0,12111,COMPLETE\n",
      "4,2013-07-25 00:00:00.0,8827,CLOSED\n",
      "5,2013-07-25 00:00:00.0,11318,COMPLETE\n",
      "6,2013-07-25 00:00:00.0,7130,COMPLETE\n",
      "7,2013-07-25 00:00:00.0,4530,COMPLETE\n",
      "8,2013-07-25 00:00:00.0,2911,PROCESSING\n",
      "9,2013-07-25 00:00:00.0,5657,PENDING_PAYMENT\n",
      "10,2013-07-25 00:00:00.0,5648,PENDING_PAYMENT\n"
     ]
    }
   ],
   "source": [
    "ordersPath = \"/data/retail_db/orders/part-00000\"\n",
    "ordersFile = open(ordersPath)\n",
    "ordersData = ordersFile.read()\n",
    "orders = ordersData.splitlines()\n",
    "for i in orders[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 'CLOSED')\n",
      "('2', 'PENDING_PAYMENT')\n",
      "('3', 'COMPLETE')\n",
      "('4', 'CLOSED')\n",
      "('5', 'COMPLETE')\n",
      "('6', 'COMPLETE')\n",
      "('7', 'COMPLETE')\n",
      "('8', 'PROCESSING')\n",
      "('9', 'PENDING_PAYMENT')\n",
      "('10', 'PENDING_PAYMENT')\n"
     ]
    }
   ],
   "source": [
    "ordersMap = map(lambda o: (o.split(\",\")[0], o.split(\",\")[3]), orders)\n",
    "for i in list(ordersMap)[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,957,1,299.98,299.98\n",
      "2,2,1073,1,199.99,199.99\n",
      "3,2,502,5,250.0,50.0\n",
      "4,2,403,1,129.99,129.99\n",
      "5,4,897,2,49.98,24.99\n",
      "6,4,365,5,299.95,59.99\n",
      "7,4,502,3,150.0,50.0\n",
      "8,4,1014,4,199.92,49.98\n",
      "9,5,957,1,299.98,299.98\n",
      "10,5,365,5,299.95,59.99\n"
     ]
    }
   ],
   "source": [
    "orderItemsPath = \"/data/retail_db/order_items/part-00000\"\n",
    "orderItemsFile = open(orderItemsPath)\n",
    "orderItemsData = orderItemsFile.read()\n",
    "orderItems = orderItemsData.splitlines()\n",
    "for i in orderItems[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579.98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderItemsFiltered = filter(lambda oi: int(oi.split(\",\")[1]) == 2, orderItems)\n",
    "orderItemsMap = map(lambda oi: float(oi.split(\",\")[4]), orderItemsFiltered)\n",
    "#sum(orderItemsMap)\n",
    "import functools as ft\n",
    "ft.reduce(lambda x, y: x + y, orderItemsMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Pandas Data Frames\n",
    "\n",
    "While collections are typically the group of objects or tuples or simple strings, we need to parse them to further process the data. With Data Frames we can define the structure and we can reference values in each record using column names in Data Frames. Also, Data Frames provide rich and simple APIs to convert CSV Files into Data Frames and process them with developer-friendly API.\n",
    "\n",
    "* Using read_csv with names we can create Data Frame out of comma-separated data with the field name\n",
    "* You can fetch data from specific columns using names\n",
    "* We can filter data using query\n",
    "* We can perform by key aggregations using group by and then aggregate functions\n",
    "* We can also join data using align\n",
    "\n",
    "Here are some of the examples of usage of Pandas data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "orderItemsPath = \"/data/retail_db/order_items/part-00000\"\n",
    "orderItems = pd.read_csv(orderItemsPath, names=[\"order_item_id\", \"order_item_order_id\", \"order_item_product_id\", \"order_item_quantity\", \"order_item_subtotal\", \"order_item_product_price\"])\n",
    "orderItems[['order_item_id', 'order_item_subtotal']]\n",
    "orderItems.query('order_item_order_id == 2')\n",
    "orderItems.query('order_item_order_id == 2')['order_item_subtotal'].sum()\n",
    "orderItems.groupby(['order_item_order_id'])['order_item_subtotal'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
